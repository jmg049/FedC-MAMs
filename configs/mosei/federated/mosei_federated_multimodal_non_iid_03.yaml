experiment: !ExperimentConfig
  name: "MOSEI Federated Learning - Non-IID - 50 Clients - 25 Rounds"
  debug: False
  device: "cuda"
  do_test: True

data:
    train:
      dataset: "mosei"
      data_fp: "DATA/MOSEI/aligned_50.pkl"
      target_modality: "multimodal"
      split: "train"
    validation:
      dataset: "mosei"
      data_fp: "DATA/MOSEI/aligned_50.pkl"
      target_modality: "multimodal"
      split: "valid"
      shuffle: True
    test:
      dataset: "mosei"
      data_fp: "DATA/MOSEI/aligned_50.pkl"
      target_modality: "multimodal"
      split: "test"
      shuffle: True
    global_fraction: 0.1
    distribution_type: "non_iid"
    sampling_strategy: "non_iid"
    alpha: 0.3  # Not used for uniform sampling, but included for completeness
    get_label_fn: "mosei"

federated: 
  server_config: !FederatedServerConfig
    num_clients: 50
    rounds: 25  # Suggested number of federated rounds
    aggregation_strategy: "fedavg"
    optimizer: "Adam"
    optimizer_kwargs:
      lr: 0.001
      weight_decay: 0.00001
    criterion: "cross_entropy"
    criterion_kwargs: {}
    epochs: 2
    logging_config: 
      save_metric: "NonZeroF1_AVL"
      log_path: "experiments/mosei_federated/logs/{experiment_name}/{run_id}/global/"
      model_output_path: "experiments/mosei_federated/models/{experiment_name}/{run_id}/global/{round}/mosei_federated_model_{save_metric}.pth"
      metrics_paths: "experiments/mosei_federated/metrics/{experiment_name}/{run_id}/global/{round}"
    early_stopping: False
    early_stopping_patience: 10
    early_stopping_metric: "loss"
    global_model_config: !ModelConfig &model
      name: "UttFusionModel"
      input_size_a: 74
      embd_size_a: 96
      embd_method_a: "maxpool"
      input_size_v: 35
      embd_size_v: 96
      embd_method_v: "maxpool"
      input_size_t: 768
      embd_size_t: 96
      classification_layers: [96, 96]
      output_dim: 3
      dropout: 0.5
      use_bn: False
  client_config: !FederatedClientConfig
    model_config: *model
    optimizer: "Adam"
    optimizer_kwargs:
      lr: 0.0001
      weight_decay: 0.00001
    criterion: "cross_entropy"
    criterion_kwargs: {}
    local_epochs: 10  
    logging: 
      save_metric: "NonZeroF1_AVL"
      log_path: "experiments/mosei_federated/logs/{experiment_name}/{run_id}/client_{client_id}/"
      model_output_path: "experiments/mosei_federated/models/{experiment_name}/{run_id}/client_{client_id}/mosei_federated_model_{save_metric}.pth"
      metrics_paths: "experiments/mosei_federated/metrics/{experiment_name}/{run_id}/client_{client_id}/"
    local_batch_size: 128
    early_stopping: False
    early_stopping_patience: 10
    early_stopping_metric: "loss"

metrics:
  metrics:
    Accuracy:
      function: "sklearn.metrics.accuracy_score"
    F1_Micro:
      function: "sklearn.metrics.f1_score"
      kwargs:
        average: "micro"
    F1_Macro:
      function: "sklearn.metrics.f1_score"
      kwargs:
        average: "macro"
    F1_Weighted:
      function: "sklearn.metrics.f1_score"
      kwargs:
        average: "weighted"
    UAR:
      function: "sklearn.metrics.recall_score"
      kwargs:
        average: "macro"
        zero_division: 0
    Precision_Macro:
      function: "sklearn.metrics.precision_score"
      kwargs:
        average: "macro"
        zero_division: 0
    Recall_Macro:
      function: "sklearn.metrics.recall_score"
      kwargs:
        average: "macro"
        zero_division: 0
    Precision_Weighted:
      function: "sklearn.metrics.precision_score"
      kwargs:
        average: "weighted"
        zero_division: 0
    Recall_Weighted:
      function: "sklearn.metrics.recall_score"
      kwargs:
        average: "weighted"
        zero_division: 0
    Precision_Micro:
      function: "sklearn.metrics.precision_score"
      kwargs:
        average: "micro"
        zero_division: 0
    Recall_Micro:
      function: "sklearn.metrics.recall_score"
      kwargs:
        average: "micro"
        zero_division: 0
    ConfusionMatrix:
      function: "sklearn.metrics.confusion_matrix"
      kwargs:
        labels: [0, 1]